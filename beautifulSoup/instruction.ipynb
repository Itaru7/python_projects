{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this miniproject, you will scrape New York Social Diary (http://www.newyorksocialdiary.com/).\n",
    "This website provides photographs from the social events that the socialites might attend. \n",
    "Each photo has a caption that labels those who appear in the photo.\n",
    "\n",
    "You have to find the unique list of the names of the total people who are annotated in the captions of the photos from the parties before December 1st, 2014. \n",
    "\n",
    "To crawl the data and see the list of the party pages go to http://www.newyorksocialdiary.com/party-pictures.\n",
    "\n",
    "# Hints for Crawling\n",
    "\n",
    "1. See how the url of each page changes when you go through different pages. Try to find a \n",
    "   plan to get all the data that you need.\n",
    "2. There are some photos with narrative captions. These captions are not useful for you. It's\n",
    "   faster to download all the captions first and filter out those you don't need later.\n",
    "3. To track the time, you can use python's **'datetime.strptime'** function to parse the date\n",
    "   that is located on each party's index page.\n",
    "4. Save your data so you don't need to re-scrape everytime you run your code. \n",
    "   You can pickle it! \"https://wiki.python.org/moin/UsingPickle\"\n",
    "\n",
    "# Hints for Parsing\n",
    "\n",
    "1. As it was mentioned there are some long narrative captinos that are not useful. Set a\n",
    "   cutoff at 250 characters for these captions.\n",
    "2. It might be better to use **'re.split'** instead of **'string.split'** when you want to\n",
    "   seperate the captions based on different punctuations.\n",
    "3. There are some titles before some names that you have to find and filter. For example,\n",
    "   \"Mayor Michael Bloomberg\" after his election and \"Michael Bloomberg\" before his election.\n",
    "   In fact, both of these refer to the same person.\n",
    "4. There are cases that couples are written as e.g. \"John and Mary Smith\". You have to parse\n",
    "   this into two separate names: \"John Smith\" and \"Mary Smith\".\n",
    "   \n",
    "# Submission\n",
    "\n",
    "Submit a zip file to Canvas. The zip file should contain your python code for scraping and a number that shows the total count of the names you could fetch from the captions.  \n",
    "\n",
    "\n",
    "# Bonus Question (10 points)\n",
    "Find \"who is the most popular\"?\n",
    "\n",
    "To answer this question, you have to find how many connections everyone has. You can think of  this problem in terms of the graph 'https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29'.\n",
    "A pair of two people in a photo is considered a link.\n",
    "You can use python's **'networkx'** library. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
